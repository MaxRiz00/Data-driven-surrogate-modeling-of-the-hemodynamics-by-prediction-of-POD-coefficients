{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Best model for pressure\n",
    "The best model for pressure is the one with the following architecture:\n",
    "- $7\\,$ input parameters and $7$ output parameters\n",
    "- $5\\,$ hidden layers with $128$ neurons each with batch normalization\n",
    "- `ReLU`,`Tanh` activation function\n",
    "- `Adam` optimizer with learning rate $0.01$\n",
    "- `ExponentialLR` scheduler with $\\gamma=0.9995$\n",
    "- `MSE` loss\n",
    "- NO $L^1$ regularization\n",
    "- $3000\\,$ epochs\n",
    "\n",
    "Make sure the folder `data` is in the principal directory.\n",
    "Importing utils will load the data and the basis functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# General setups and imports\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "if device==\"cuda:0\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalization of input parameters in range [0,1]\n",
    "maxs = np.array([8.0, 0.3, 0.5, 0.5, 0.5, 0.0])\n",
    "mins = np.array([4.0, 0.1, -0.1, -0.5, -0.5, -0.3])\n",
    "for i in range(params.shape[1]):\n",
    "    params[:, i] = (params[:, i] - mins[i]) / (maxs[i] - mins[i])\n",
    "\n",
    "\n",
    "# Shuffle the parameters\n",
    "idx = np.random.permutation(params.shape[0])\n",
    "params = params[idx]\n",
    "\n",
    "# Expand pressure in time\n",
    "pressure_time = solutions['pressure'] @ basis_time['pressure'].T\n",
    "\n",
    "# Shuffle the pressure, the parameters are shuffled in the same way\n",
    "pressure_time = pressure_time[idx]\n",
    "\n",
    "# Split the data into training, validation and test set\n",
    "\n",
    "# Training set: 80% of the data\n",
    "# Validation set: 10% of the data\n",
    "# Test set: 10% of the data\n",
    "\n",
    "# Training set\n",
    "params_train = params[:int(0.8 * len(params))]\n",
    "pressure_time_train = pressure_time[:int(0.8 * len(params))]\n",
    "\n",
    "# Validation set\n",
    "params_val = params[int(0.8 * len(params)):int(0.9 * len(params))]\n",
    "pressure_time_val = pressure_time[int(0.8 * len(params)):int(0.9 * len(params))]\n",
    "\n",
    "# Test set\n",
    "params_test = params[int(0.9 * len(params)):]\n",
    "pressure_time_test = pressure_time[int(0.9 * len(params)):]\n",
    "\n",
    "\n",
    "# Treat time as a parameter: add it to the parameter list\n",
    "# u1 u2 u3 u4 u5 u6 t \n",
    "times = np.linspace(0, 1, 300)\n",
    "\n",
    "#sample all the times with times[:] \n",
    "#sample every 5 timesteps with times[::5] \n",
    "times_test= times[:]\n",
    "times_train= times[:]\n",
    "times_val= times[:]\n",
    "\n",
    "# generate a matrix with parameters for each time step for training, validation and test set\n",
    "# add time to the parameter vector\n",
    "params_time_train = np.repeat(params_train, len(times_train), axis=0)\n",
    "params_time_train = np.hstack((params_time_train, np.tile(times_train, len(params_train)).reshape(-1, 1)))\n",
    "\n",
    "params_time_val = np.repeat(params_val, len(times_val), axis=0)\n",
    "params_time_val = np.hstack((params_time_val, np.tile(times_val, len(params_val)).reshape(-1, 1)))\n",
    "\n",
    "params_time_test = np.repeat(params_test, len(times_test), axis=0)\n",
    "params_time_test = np.hstack((params_time_test, np.tile(times_test, len(params_test)).reshape(-1, 1)))\n",
    "\n",
    "# if times[:] put vel_time_test[:, :, :]\n",
    "# if times[::5] put vel_time_test[:, :, ::5] \n",
    "pressure_model_test= pressure_time_test[:, :, :]\n",
    "pressure_model_train= pressure_time_train[:, :, :]\n",
    "pressure_model_val= pressure_time_val[:, :, :]\n",
    "\n",
    "# Reshape the data to have the form (number of samples, number of parameters, number of time steps)\n",
    "pressure_model_train = pressure_model_train.transpose(0, 2, 1).reshape((pressure_model_train.shape[0] * len(times_train)), 7)\n",
    "pressure_model_val = pressure_model_val.transpose(0, 2, 1).reshape((pressure_model_val.shape[0] * len(times_val)), 7)\n",
    "pressure_model_test = pressure_model_test.transpose(0, 2, 1).reshape((pressure_model_test.shape[0] * len(times_test)), 7)\n",
    "\n",
    "# Take the SV coefficients of the pressure and normalize them\n",
    "sv_space_pressure = sv_space['pressure']\n",
    "sv_space_pressure = sv_space_pressure / np.sum(sv_space_pressure)\n",
    "\n",
    "\n",
    "# Convert to tensor\n",
    "params_time_train = torch.tensor(params_time_train, dtype=torch.float32).to(device)\n",
    "params_time_val = torch.tensor(params_time_val, dtype=torch.float32).to(device)\n",
    "params_time_test = torch.tensor(params_time_test, dtype=torch.float32).to(device)\n",
    "\n",
    "pressure_model_train = torch.tensor(pressure_model_train, dtype=torch.float32).to(device)\n",
    "pressure_model_val = torch.tensor(pressure_model_val, dtype=torch.float32).to(device)\n",
    "pressure_model_test = torch.tensor(pressure_model_test, dtype=torch.float32).to(device)\n",
    "\n",
    "sv_space_pressure = torch.tensor(sv_space_pressure, dtype=torch.float32).to(device)\n",
    "sv_space_pressure = sv_space_pressure.reshape(7, 1)\n",
    "\n",
    "# Possible logarithmic transformation of the data\n",
    "#pressure_model_train = torch.log(torch.abs(pressure_model_train) + 1) * torch.sign(pressure_model_train)\n",
    "#pressure_model_val = torch.log(torch.abs(pressure_model_val) + 1) * torch.sign(pressure_model_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class Net(torch.nn.Module):\n",
    "    # 7 input parameters, corresponding to: u1 u2 u3 u4 u5 u6 t\n",
    "    # 7 output parameters, corresponding to the POD (reduced) coefficients of the pressure solution\n",
    "    # 5 hidden layers with 128 neurons each with batch normalization\n",
    "    # ReLU,Tanh activation function\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.ReLU()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F3 = torch.nn.ReLU()\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F4 = torch.nn.Tanh()\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc5 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F5 = torch.nn.ReLU()\n",
    "        self.batch_norm5 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc6 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.F3(self.fc3(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.F4(self.fc4(x))\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.F5(self.fc5(x))\n",
    "        x = self.batch_norm5(x)\n",
    "        return self.fc6(x)\n",
    "\n",
    "\n",
    "# Define the parameters of the network\n",
    "input_size = 7\n",
    "hidden_size = 128 # constant for all the layers\n",
    "output_size = 7\n",
    "\n",
    "# Create the network\n",
    "net = Net(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "# Define the loss function, weighting the pressure loss with the sqrt sv coefficients\n",
    "#def loss_fn(y_pred, y_true):\n",
    "#    return torch.mean(torch.mm((y_pred - y_true) ** 2, (sv_space_pressure)**(1/2)))\n",
    "\n",
    "# Define the loss function as the MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "learning_rate = .01 # Starting learning rate\n",
    "#optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9995  # The factor by which the learning rate will be multiplied at each epoch\n",
    "\n",
    "# Create the ExponentialLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "# L1 regularization if needed\n",
    "l1_lambda = 0 # Set to 0 if you do not want to use L1 regularization\n",
    "\n",
    "if l1_lambda > 0:\n",
    "    print(\"L1 regularization enabled\")\n",
    "    nweights = 0\n",
    "    for name,weights in net.named_parameters():\n",
    "        if 'bias' not in name:\n",
    "            nweights = nweights + weights.numel()\n",
    "    print(f'Total number of weights in the model = {nweights}')\n",
    "else:\n",
    "    print(\"L1 regularization disabled\")\n",
    "\n",
    "\n",
    "# Save the loss functions for each iteration\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "# Save the absolute errors every 100 iteration (for memory reasons)\n",
    "err_val = []\n",
    "err_train = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCBS1AlNJ6oc"
   },
   "outputs": [],
   "source": [
    "# Load the model and the losses if present, run this cell if you do not want to train or if you want to continue a previous training\n",
    "\n",
    "if os.path.exists(\"losses_val_pressure.npy\"):\n",
    "   losses_train = np.load(\"losses_val_pressure.npy\").tolist()\n",
    "if os.path.exists(\"losses_train_pressure.npy\"):\n",
    "   losses_val = np.load(\"losses_train_pressure.npy\").tolist()\n",
    "\n",
    "if os.path.exists(\"model_pressure.pt\"):\n",
    "    net.load_state_dict(torch.load(\"model_pressure.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XEsNjmCBtvY",
    "outputId": "c257ff95-48eb-47f8-c2ce-8593a97b50b0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702911246605,
     "user_tz": -60,
     "elapsed": 430285,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     }
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Train the network\"\"\"\n",
    "\n",
    "for t in range(3000):\n",
    "    net.train()\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = net(params_time_train).to(device)\n",
    "\n",
    "    # if you want to compute the training error every 100 iterations\n",
    "    \"\"\"\n",
    "    if t %100 ==0:\n",
    "      # compute the mean across the time steps for each simulation\n",
    "      mean_pres=torch.mean(torch.norm(pressure_model_train, dim=1).reshape(-1, len(times_train)), dim=1)\n",
    "      # repeat the mean for every time step\n",
    "      mean_pres = torch.repeat(mean_pres, [len(times_train),1]).reshape(1, -1)\n",
    "      # compute the absolute error for each simulation \n",
    "      abs_error = torch.norm(y_pred - pressure_model_train, dim=1)/mean_pres\n",
    "      \n",
    "      err_train.append(torch.mean(abs_error).to(\"cpu\").detach().numpy())\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Compute train loss\n",
    "    loss_train = loss_fn(y_pred, pressure_model_train)\n",
    "\n",
    "    losses_train.append(loss_train.item())\n",
    "\n",
    "    # L1 regularization if needed\n",
    "    \n",
    "    if l1_lambda > 0:\n",
    "        # Compute L1 term\n",
    "        L1_term = torch.tensor(0., requires_grad=True).to(device)\n",
    "        for name, weights in net.named_parameters():\n",
    "            if 'bias' not in name:\n",
    "                    weights_sum = torch.sum(torch.abs(weights))\n",
    "                    L1_term = L1_term + weights_sum\n",
    "        L1_term = L1_term / nweights\n",
    "        # Regularize loss using L1 regularization\n",
    "        loss_train = loss_train + L1_term * l1_lambda\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all the gradients for the variables it will update (which are the learnable weights of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss_train.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_val = net(params_time_val).to(device)\n",
    "        loss_val = loss_fn(y_pred_val, pressure_model_val)\n",
    "        \n",
    "        # if you want to  compute the relative error every 100 iterations\n",
    "        \"\"\"\n",
    "        if t%100==0:\n",
    "          # compute the mean across the time steps for each simulation\n",
    "          mean_pres=torch.mean(torch.norm(pressure_model_val, dim=1).reshape(-1, len(times_val)), dim=1)\n",
    "          # repeat the mean for every time step\n",
    "          mean_pres = torch.repeat(mean_pres, [len(times_val),1]).reshape(1, -1)\n",
    "          # compute the absolute error for each simulation\n",
    "          abs_error = torch.norm(y_pred_val - pressure_model_val, dim=1)/mean_pres\n",
    "          print(\"Validation, \" , torch.mean(abs_error))\n",
    "\n",
    "          err_val.append(torch.mean(abs_error).to(\"cpu\").detach().numpy())\n",
    "        \"\"\"\n",
    "    losses_val.append(loss_val.item()) \n",
    "    \n",
    "    if t % 100 == 0:\n",
    "        print(\"Epoch: \", t, \"Train Loss: \", loss_train.item(),\", Validation Loss: \", loss_val.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model and losses, run this cell if you want to save the model and the losses\n",
    "torch.save(net.state_dict(), \"model_pressure.pt\")\n",
    "np.save(\"losses_val_pressure.npy\", losses_val)\n",
    "np.save(\"losses_train_pressure.npy\", losses_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1702911249709,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     },
     "user_tz": -60
    },
    "id": "jJSvbo2xgEBo",
    "outputId": "2f747814-1255-4710-c9a9-892e1c8fda66"
   },
   "outputs": [],
   "source": [
    "\"\"\" Test the network\"\"\"\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = net(params_time_test)\n",
    "y_pred_numpy=y_pred.to(\"cpu\")\n",
    "\n",
    "# convert the output of the NN to numpy array\n",
    "y_pred_numpy = y_pred_numpy.detach().numpy()\n",
    "\n",
    "# if you have considered the logarithmic transformation you have to perform the inverse transformation\n",
    "#y_pred_numpy=np.exp(y_pred_numpy)-1\n",
    "\n",
    "# convert the pressure_model_test to numpy\n",
    "pressure_model_test_numpy=pressure_model_test.to(\"cpu\")\n",
    "pressure_model_test_numpy=pressure_model_test_numpy.detach().numpy()\n",
    "\n",
    "# Compute and print loss.\n",
    "loss_t = torch.nn.MSELoss()(y_pred, pressure_model_test)\n",
    "\n",
    "print(\"Test loss: \", loss_t.item())\n",
    "\n",
    "# Compute the relative error\n",
    "\n",
    "rel_error = np.linalg.norm(y_pred_numpy - pressure_model_test_numpy, axis=1) / np.linalg.norm(pressure_model_test_numpy, axis=1)\n",
    "\n",
    "#Compute average values\n",
    "mean_pres=np.mean(np.linalg.norm(pressure_model_test_numpy, axis=1).reshape(-1, len(times_test)), axis=1)\n",
    "# repeat the mean for every time step\n",
    "mean_pres = np.repeat(mean_pres, len(times_test)).reshape(1, -1)\n",
    "#Compute absolute error rescaled by average values within each simulation\n",
    "abs_error = np.linalg.norm(y_pred_numpy - pressure_model_test_numpy, axis=1)/mean_pres\n",
    "abs_error = abs_error.T\n",
    "\n",
    "#np.save(\"abs_error_pressure.npy\", abs_error)\n",
    "print(\"Relative error: \", np.mean(rel_error))\n",
    "print(\"Absolute error: \", np.mean(abs_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1702910380122,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     },
     "user_tz": -60
    },
    "id": "HaImGHZ0gMsZ",
    "outputId": "be53b491-7935-4f88-828b-3b7e1b006e8a"
   },
   "outputs": [],
   "source": [
    "# Plot the losses function\n",
    "\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses for pressure\")\n",
    "plt.savefig(\"losses_pressure.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot the train and validation error across the epochs, if computed\n",
    "\n",
    "plt.plot(err_train, label=\"train\")\n",
    "plt.plot(err_val, label=\"val\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "x_ticks_locations = np.arange(0, 40, 5)\n",
    "xs=np.arange(0,4000, 500)\n",
    "x_ticks_labels = [str(int(label)) for label in xs]\n",
    "plt.xticks(x_ticks_locations, x_ticks_labels)\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"Absolute error pressure\")\n",
    "#plt.savefig(\"absolute_error_pressure.png\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "j9rZnDiVHVYG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702908967854,
     "user_tz": -60,
     "elapsed": 745,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     }
    },
    "outputId": "0f8429df-75c5-4c36-cf71-4e91fc43f409"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Time-space error\"\"\"\n",
    "\n",
    "# Reshape and transpose the data to have the form (number of samples, number of space coefficients, number of time steps)\n",
    "Test = np.zeros((len(params_test), len(times_test), 7))\n",
    "for i in range(len(params_test)):\n",
    "    Test[i, :, :] = y_pred_numpy[i * len(times_test):(i + 1) * len(times_test), :]\n",
    "Test = Test.transpose(0, 2, 1)\n",
    "\n",
    "# Take the true solution\n",
    "TrUE = pressure_time_test[:, :, :]\n",
    "\n",
    "# compute the space norm of the error\n",
    "norm_s = np.linalg.norm(Test - TrUE, axis=1)\n",
    "\n",
    "# compute the time norm of norm_s to obtain the time-space norm of the error\n",
    "norm_st = np.linalg.norm(norm_s, axis=1)\n",
    "\n",
    "# compute the space norm of the true solution\n",
    "norm_s_TRUE = np.linalg.norm(TrUE, axis=1)\n",
    "\n",
    "# compute the time norm to obtain the time-space norm of the true solution\n",
    "norm_st_TRUE = np.linalg.norm(norm_s_TRUE, axis=1)\n",
    "\n",
    "# compute the final error\n",
    "err_vec = np.divide(norm_st, norm_st_TRUE)\n",
    "\n",
    "# print the mean and the standard deviation of the error\n",
    "print(\"Mean error=\", np.mean(err_vec))\n",
    "print(\"Standard deviation=\", np.std(err_vec))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ekswxa_y2AF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702910401262,
     "user_tz": -60,
     "elapsed": 718,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     }
    },
    "outputId": "eb36bf06-c8c9-4d65-e670-57c4fa93410d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the solution\n",
    "After training the network, you can visualize the solution in space-time.\n",
    "Open the group of generated files with `Paraview`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" Visualize the solution of the pressure in space-time.\"\"\"\n",
    "# Save predicted solution in a vtk file for visualization in Paraview\n",
    "params_for_simulation=params_time_test[:301, :]\n",
    "\n",
    "sol_pred = net(params_for_simulation).to(device)\n",
    "sol_pred=sol_pred.to(\"cpu\")\n",
    "sol_pred=sol_pred.detach().numpy()\n",
    "\n",
    "params = np.load(os.path.join('../data/RB_data', 'parameters.npy'))\n",
    "params = np.delete(params, 2, axis=1)\n",
    "\n",
    "# create a new folder for the solutions\n",
    "os.makedirs('solutions_pred', exist_ok=True)\n",
    "\n",
    "# read the mesh and create cur_idxs\n",
    "idxs = compute_matching_idxs()\n",
    "mesh = read_vtk(os.path.join('../data/geometries', 'tube_1x4.vtu'))\n",
    "fom_solution = dict()\n",
    "field = 'pressure'\n",
    "\n",
    "cur_idxs = np.hstack([idxs + k * (Nh_space[field] // 1) for k in range(1)])\n",
    "\n",
    "# expand the solution in space\n",
    "fom_solution[field] = basis_space['pressure'].dot(sol_pred.T)[cur_idxs]\n",
    "# fix the time step for the visualization\n",
    "step_t = 5\n",
    "\n",
    "# add the solution to the mesh and write the vtk file for visualization in Paraview\n",
    "for cnt_t in range(0, Nh_time['pressure'], step_t):\n",
    "    cur_fom_solution = np.reshape(fom_solution[field][:, cnt_t], (1, -1)).T\n",
    "    mesh = add_array(mesh, cur_fom_solution, field)\n",
    "\n",
    "    write_vtk(mesh, os.path.join('solutions_pred', f\"pressure_{0}_{cnt_t}\" + '.vtu'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
