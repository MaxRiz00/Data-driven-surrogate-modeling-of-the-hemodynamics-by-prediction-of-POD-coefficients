{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## GRID SEARCH for pressure\n",
    "\n",
    " \n",
    "This code is used to find the best architecture for the NN for the pressure, we try with different number of hidden layers and different number of neurons in each layer. You can run the code for each architecture and then compare the results to find the best one.\n",
    "\n",
    "This code was run in a local machine without a GPU.\n",
    "\n",
    "Make sure the `data` folder is in the principal directory.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe9f9390e79cb57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General setups and imports\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "if device==\"cuda:0\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalization of input parameters in [0,1]\n",
    "maxs = np.array([8.0, 0.3, 0.5, 0.5, 0.5, 0.0])\n",
    "mins = np.array([4.0, 0.1, -0.1, -0.5, -0.5, -0.3])\n",
    "for i in range(params.shape[1]):\n",
    "    params[:, i] = (params[:, i] - mins[i]) / (maxs[i] - mins[i])\n",
    "\n",
    "\n",
    "# shuffle the parameters\n",
    "idx = np.random.permutation(params.shape[0])\n",
    "params = params[idx]\n",
    "\n",
    "# Expand pressure in time\n",
    "pressure_time = solutions['pressure'] @ basis_time['pressure'].T\n",
    "\n",
    "# shuffle the pressure, the parameters are shuffled in the same way\n",
    "pressure_time = pressure_time[idx]\n",
    "\n",
    "# Split the data into training, validation and test set\n",
    "\n",
    "# Training set: 80% of the data\n",
    "# Validation set: 10% of the data\n",
    "# Test set: 10% of the data\n",
    "\n",
    "# Training set\n",
    "params_train = params[:int(0.8 * len(params))]\n",
    "pressure_time_train = pressure_time[:int(0.8 * len(params))]\n",
    "\n",
    "# Validation set\n",
    "params_val = params[int(0.8 * len(params)):int(0.9 * len(params))]\n",
    "pressure_time_val = pressure_time[int(0.8 * len(params)):int(0.9 * len(params))]\n",
    "\n",
    "\n",
    "# Test set\n",
    "params_test = params[int(0.9 * len(params)):]\n",
    "pressure_time_test = pressure_time[int(0.9 * len(params)):]\n",
    "\n",
    "\n",
    "# Treat time as a parameter: add it to the parameter list\n",
    "# u1 u2 u3 u4 u5 u6 t\n",
    "times = np.linspace(0, 1, 300)\n",
    "\n",
    "#sample all the times with times[:] \n",
    "#sample every 5 timesteps with times[::5] \n",
    "times_test= times[::5]\n",
    "times_train= times[::5]\n",
    "times_val= times[::5]\n",
    "\n",
    "# generate a matrix of new parameters copying parameter vector for each time step for train, validation and test set\n",
    "# Add the time as last parameter\n",
    "\n",
    "params_time_train = np.repeat(params_train, len(times_train), axis=0)\n",
    "params_time_train = np.hstack((params_time_train, np.tile(times_train, len(params_train)).reshape(-1, 1)))\n",
    "\n",
    "params_time_val = np.repeat(params_val, len(times_val), axis=0)\n",
    "params_time_val = np.hstack((params_time_val, np.tile(times_val, len(params_val)).reshape(-1, 1)))\n",
    "\n",
    "params_time_test = np.repeat(params_test, len(times_test), axis=0)\n",
    "params_time_test = np.hstack((params_time_test, np.tile(times_test, len(params_test)).reshape(-1, 1)))\n",
    "\n",
    "# if times[:] put vel_time_test[:, :, :]\n",
    "# if times[::5] put vel_time_test[:, :, ::5] \n",
    "pressure_model_test= pressure_time_test[:, :, ::5]\n",
    "pressure_model_train= pressure_time_train[:, :, ::5]\n",
    "pressure_model_val= pressure_time_val[:, :, ::5]\n",
    "\n",
    "# Reshape the data to have the form (number of samples, number of parameters, number of time steps)\n",
    "pressure_model_train = pressure_model_train.transpose(0, 2, 1).reshape((pressure_model_train.shape[0] * len(times_train)), 7)\n",
    "pressure_model_val = pressure_model_val.transpose(0, 2, 1).reshape((pressure_model_val.shape[0] * len(times_val)), 7)\n",
    "pressure_model_test = pressure_model_test.transpose(0, 2, 1).reshape((pressure_model_test.shape[0] * len(times_test)), 7)\n",
    "\n",
    "# Normalize the SV coefficients of the pressure\n",
    "sv_space_pressure = sv_space['pressure']\n",
    "sv_space_pressure = sv_space_pressure / np.sum(sv_space_pressure)\n",
    "\n",
    "\n",
    "# Convert to tensor\n",
    "params_time_train = torch.tensor(params_time_train, dtype=torch.float32).to(device)\n",
    "params_time_val = torch.tensor(params_time_val, dtype=torch.float32).to(device)\n",
    "params_time_test = torch.tensor(params_time_test, dtype=torch.float32).to(device)\n",
    "\n",
    "pressure_model_train = torch.tensor(pressure_model_train, dtype=torch.float32).to(device)\n",
    "pressure_model_val = torch.tensor(pressure_model_val, dtype=torch.float32).to(device)\n",
    "pressure_model_test = torch.tensor(pressure_model_test, dtype=torch.float32).to(device)\n",
    "\n",
    "sv_space_pressure = torch.tensor(sv_space_pressure, dtype=torch.float32).to(device)\n",
    "sv_space_pressure = sv_space_pressure.reshape(7, 1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a25dc7207fae484"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Choose the architecture of the network, run only the cell corresponding to the architecture you want to use\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe7b4e4954baf67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2 hidden layers with K neurons each with batch normalization\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.Tanh()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4a621c3d655f5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3 hidden layers with K neurons each with batch normalization\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.Tanh()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F3 = torch.nn.Tanh()\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.F3(self.fc3(x))\n",
    "        return self.fc4(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33094e02bb52b3ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4 hidden layers with K neurons each with batch normalization\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.Tanh()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F3 = torch.nn.Tanh()\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.F4 = torch.nn.Tanh()\n",
    "        self.fc5 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.F3(self.fc3(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.F4(self.fc4(x))\n",
    "        return self.fc5(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2378d629691242f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 hidden layers with K neurons each with batch normalization\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.ReLU()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F3 = torch.nn.ReLU()\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F4 = torch.nn.Tanh()\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc5 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F5 = torch.nn.ReLU()\n",
    "        self.fc6 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.F3(self.fc3(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.F4(self.fc4(x))\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.F5(self.fc5(x))\n",
    "        return self.fc6(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ae8a62b08082a1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change the value of the variable `hidden_size` to change the number of neurons in the hidden layer. \n",
    "\n",
    "The number of hidden layers is determined by the architecture of the network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c9f304983c29dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dimension of the network\n",
    "\n",
    "input_size = 7\n",
    "# Choose the number of neurons in the hidden layer\n",
    "hidden_size = 128 # Change the number of neurons in the hidden layer, we tried with 32, 64, 128, 256\n",
    "output_size = 7 # POD coefficients for the pressure\n",
    "\n",
    "# Create the network\n",
    "net = Net(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "\n",
    "learning_rate = .01 # Starting learning rate\n",
    "\n",
    "# Use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Save the loss function for each iteration\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "# Save the absolute error for each iteration\n",
    "err_val = []\n",
    "err_train = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "834803c6064043b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training of the network, the loss function is saved for each iteration. \n",
    "The network is trained for $1500$ epochs, you can change the number of epochs by changing the value of the variable `n_epochs`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdca52fa55654033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_epochs = 1500 # Number of epochs\n",
    "\n",
    "for t in range(n_epochs):\n",
    "    net.train()\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = net(params_time_train).to(device)\n",
    "\n",
    "    # Compute train loss\n",
    "    loss_train = loss_fn(y_pred, pressure_model_train)\n",
    "\n",
    "    losses_train.append(loss_train.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of #the gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss_train.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_val = net(params_time_val).to(device)\n",
    "        loss_val = loss_fn(y_pred_val, pressure_model_val)\n",
    "        \n",
    "    if t % 100 == 0:\n",
    "        print(\"Epoch: \", t, \"Train Loss: \", loss_train.item(),\", Validation Loss: \", loss_val.item())\n",
    "        \n",
    "    losses_val.append(loss_val.item())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad724394a32e233"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test the network on the test set, the relative and absolute error are computed and printed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "153dd2b4d0196701"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" Test the network\"\"\"\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = net(params_time_test).to(\"cpu\")\n",
    "\n",
    "# convert the output of the NN to numpy array\n",
    "y_pred_numpy = y_pred.detach().numpy()\n",
    "\n",
    "# convert the pressure_model_test to numpy\n",
    "pressure_model_test_numpy=pressure_model_test.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# Compute and print loss.\n",
    "loss_t = torch.nn.MSELoss()(y_pred, pressure_model_test.to(\"cpu\"))\n",
    "\n",
    "print(\"Test loss: \", loss_t.item())\n",
    "\n",
    "# Compute the relative error\n",
    "\n",
    "rel_error = np.linalg.norm(y_pred_numpy - pressure_model_test_numpy, axis=1) / np.linalg.norm(pressure_model_test_numpy, axis=1)\n",
    "\n",
    "#Compute average values \n",
    "mean_pres=np.mean(np.linalg.norm(pressure_model_test_numpy, axis=1).reshape(-1, len(times_test)), axis=1)\n",
    "\n",
    "# repeat the mean for every time step\n",
    "mean_pres = np.repeat(mean_pres, len(times_test)).reshape(1, -1)\n",
    "\n",
    "#Compute absolute error rescaled by average values within each simulation\n",
    "abs_error = np.linalg.norm(y_pred_numpy - pressure_model_test_numpy, axis=1)/mean_pres\n",
    "abs_error = abs_error.T\n",
    "\n",
    "print(\"Relative error: \", np.mean(rel_error))\n",
    "print(\"Absolute error: \", np.mean(abs_error))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df5d56351b77e2e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "508102a38eceee40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
