{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CROSS VALIDATION for pressure\n",
    "\n",
    "\n",
    "Code used for the cross validation of the neural network for the pressure. It is used to assess :\n",
    "- the performance of the different models implemented\n",
    "- fine tuning of some hyperparameters (learning rate, $\\gamma$ coefficient for exponential scheduler, $\\lambda$ coefficient for $L^1$ regularization )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11551,
     "status": "ok",
     "timestamp": 1702901864141,
     "user": {
      "displayName": "massimo gelistri",
      "userId": "05519720333501875022"
     },
     "user_tz": -60
    },
    "id": "51TM-cfvCD3a"
   },
   "outputs": [],
   "source": [
    "# General setups and imports\n",
    "from utils import *\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# initialization and seeds setup: the choice of these seeds has been fixed for reproducibility\n",
    "if device==\"cuda:0\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Normalization of input parameters in [0, 1] range\n",
    "# u1 u2 u3 u4 u5 u6\n",
    "maxs = np.array([8.0, 0.3, 0.5, 0.5, 0.5, 0.0])\n",
    "mins = np.array([4.0, 0.1, -0.1, -0.5, -0.5, -0.3])\n",
    "for i in range(params.shape[1]):\n",
    "    params[:, i] = (params[:, i] - mins[i]) / (maxs[i] - mins[i])\n",
    "\n",
    "\n",
    "# Treat time as a parameter: add it to the parameter list\n",
    "# u1 u2 u3 u4 u5 u6 t\n",
    "#consider all the times of the simulations in [0,1] range\n",
    "times = np.linspace(0, 1, 300)\n",
    "# sample all the times for the test set\n",
    "times_test= times\n",
    "#sample all the times of training set if times[::] is written below\n",
    "#sample every 5 timesteps of the simulation if times[::5] is written below\n",
    "times_train= times[::]\n",
    "\n",
    "# shuffle the parameters (order of the simulations) to perform a random splitting of the dataset \n",
    "# inside the cross validation function defined below\n",
    "idx = np.random.permutation(params.shape[0])\n",
    "params = params[idx]\n",
    "\n",
    "\n",
    "# Expand pressure in time through matrix multiplication\n",
    "pressure_time = solutions['pressure'] @ basis_time['pressure'].T\n",
    "\n",
    "# shuffle the pressure values, according to the order of parameters (simulations) defined above\n",
    "pressure_time = pressure_time[idx]\n",
    "\n",
    "# setting the Neural Network: all the modifications to the number of hidden layers, batch normalization layers \n",
    "# and activation functions can be implemented into \"Net\" defined below\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    # 7 input parameters, corresponding to: u1 u2 u3 u4 u5 u6 t\n",
    "    # 7 output parameters, corresponding to the POD (reduced) coefficients of the pressure solution\n",
    "    \n",
    "    # 5 hidden layers with 128 neurons each with batch normalization\n",
    "    # ReLU,Tanh activation function\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.F1 = torch.nn.ReLU()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F2 = torch.nn.Tanh()\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F3 = torch.nn.ReLU()\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F4 = torch.nn.Tanh()\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc5 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.F5 = torch.nn.ReLU()\n",
    "        self.batch_norm5 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc6 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.F1(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.F2(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.F3(self.fc3(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.F4(self.fc4(x))\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.F5(self.fc5(x))\n",
    "        x = self.batch_norm5(x)\n",
    "        return self.fc6(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each fold, the network is trained for `n_epochs` . The relative error, absolute error and test loss are computed. The process is repeated `k_fold` times and the mean values of the relative error, the absolute error and the test loss are computed in the end over all the folds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0baOjielITFx"
   },
   "outputs": [],
   "source": [
    "# K-fold cross validation\n",
    "def cross_validation(k_indices, k, n_epoch):\n",
    "    \n",
    "    #input:\n",
    "    # k_indices: array of indices for the k-th fold\n",
    "    # k: index of the fold\n",
    "    # n_epoch: number of epochs for training\n",
    "    \n",
    "    #output:\n",
    "    #relative error, absolute error and test loss within each test fold\n",
    "    \n",
    "    #print the current k considered as test set\n",
    "    print (\"Cross validation, k = \", k)\n",
    "    #extract the indexes of the k folder for test\n",
    "    test_indices = k_indices[k]\n",
    "    #extract the remaining indexes for the training set\n",
    "    train_indices = k_indices[np.arange(len(k_indices)) != k].flatten()\n",
    "\n",
    "    # Training set\n",
    "    \n",
    "    # select the corresponding training parameters (simulations) according to the train_indices\n",
    "    params_train = params[train_indices]\n",
    "    # add time to the parameters vector \n",
    "    params_time_train = np.repeat(params_train, len(times_train), axis=0)\n",
    "    params_time_train = np.hstack((params_time_train, np.tile(times_train, len(params_train)).reshape(-1, 1)))\n",
    "    #extract the corresponding pressure values for the input parameters and time\n",
    "    pressure_time_train = pressure_time[train_indices]\n",
    "    #sample the pressure values. if [:,:,::] is set, all times are considered.\n",
    "    #otherwise, with [:,:,::5] the solution is sampled every 5 time steps\n",
    "    pressure_model_train = pressure_time_train[:, :, ::]\n",
    "    #reshape the training set in order to have 7 POD coefficients of pressure solution for each simulation and time\n",
    "    pressure_model_train = pressure_model_train.transpose(0, 2, 1).reshape((int(pressure_model_train.shape[0]) * len(times_train)), 7)\n",
    "\n",
    "    # Testing set\n",
    "    # select the corresponding test parameters (simulations) according to the test_indices\n",
    "    params_test = params[test_indices]\n",
    "    #add time to the parameters vector \n",
    "    params_time_test = np.repeat(params_test, len(times_test), axis=0)\n",
    "    params_time_test = np.hstack((params_time_test, np.tile(times_test, len(params_test)).reshape(-1, 1)))\n",
    "    #extract the corresponding pressure values for the input parameters and time (all times will be considered in this case)\n",
    "    pressure_model_test = pressure_time[test_indices]\n",
    "    #reshape the test set in order to have 7 POD coefficients of pressure solution for each simulation and time\n",
    "    pressure_model_test = pressure_model_test.transpose(0, 2, 1).reshape((int(pressure_model_test.shape[0]) * len(times_test)), 7)\n",
    "\n",
    "    # Convert to tensor\n",
    "    params_time_train = torch.tensor(params_time_train, dtype=torch.float32).to(device)\n",
    "    params_time_test = torch.tensor(params_time_test, dtype=torch.float32).to(device)\n",
    "    pressure_model_train = torch.tensor(pressure_model_train, dtype=torch.float32).to(device)\n",
    "    #with this implementation, converting also pressure_model_test is not necessary\n",
    "    #pressure_model_test = torch.tensor(pressure_model_test, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # Train the network\n",
    "\n",
    "    #the network can be defined below choosing the input size, hidden size (same for each hidden layer) and output size\n",
    "    input_size = 7 # u1 u2 u3 u4 u5 u6 t\n",
    "    hidden_size = 128 #parameter to choose the hidden size\n",
    "    output_size = 7 #number of POD coefficients to be predicted for pressure\n",
    "\n",
    "    # Create the network\n",
    "    net = Net(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    # choice of learning rate\n",
    "    learning_rate = .01\n",
    "    # The factor by which the learning rate will be multiplied at each epoch in case\n",
    "    #exponenetial scheduler is defined\n",
    "    gamma = 0.9995  # The factor by which the learning rate will be multiplied at each epoch\n",
    "\n",
    "    # choice of the optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create the ExponentialLR scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    # initialize the losses vector\n",
    "    losses_train = []\n",
    "\n",
    "    for t in range(n_epoch):\n",
    "        #set the model to train mode\n",
    "        net.train()\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = net(params_time_train).to(device)\n",
    "\n",
    "        ## Compute the loss and put the value in the vector\n",
    "        loss_train = loss_fn(y_pred, pressure_model_train)\n",
    "        losses_train.append(loss_train.item())\n",
    "\n",
    "        #print loss every 100 epochs\n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \", t, \"Loss: \", loss_train.item())\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to set zero all the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss_train.backward()\n",
    "\n",
    "        # Calling the step function on an optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #apply the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    # Test the network\n",
    "    #predict the values for pressure\n",
    "    y_pred_test = net(params_time_test)\n",
    "    y_pred_cpu=y_pred_test.to(\"cpu\")\n",
    "    # convert the output of the NN to numpy array\n",
    "    y_pred_numpy = y_pred_cpu.detach().numpy()\n",
    "\n",
    "    # Compute the loss on the test set\n",
    "    loss_t = torch.nn.MSELoss()(y_pred_cpu, torch.tensor(pressure_model_test, dtype=torch.float32))\n",
    "\n",
    "    #print the test loss\n",
    "    print(\"Test loss: \", loss_t.item())\n",
    "\n",
    "    \n",
    "    # Compute relative error:\n",
    "    rel_error = np.linalg.norm(y_pred_numpy - pressure_model_test, axis=1) / np.linalg.norm(pressure_model_test, axis=1)\n",
    "    \n",
    "    #Compute absolute error rescaled by average values:\n",
    "    #Compute average values\n",
    "    aux = np.linalg.norm(pressure_model_test, axis=1)\n",
    "    mean_vel = np.mean(aux.reshape(-1, len(times_test)), axis=1)\n",
    "    mean_vel = np.repeat(mean_vel, len(times_test)).reshape(1, -1)\n",
    "    #rescale the absolute error by the average values within each simulation\n",
    "    abs_error = np.linalg.norm(y_pred_numpy - pressure_model_test, axis=1) / mean_vel\n",
    "    #transpose the vector\n",
    "    abs_error = abs_error.T\n",
    "    \n",
    "    print(\"Relative error: \", np.mean(rel_error))\n",
    "    print(\"Absolute error: \", np.mean(abs_error))\n",
    "    return np.mean(rel_error), np.mean(abs_error), loss_t.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#code to run the cross validation\n",
    "\n",
    "rel_errors = []\n",
    "abs_errors = []\n",
    "test_losses = []\n",
    "\n",
    "#define the number of folds\n",
    "k_fold = 5\n",
    "#define the size of each fold\n",
    "interval = int(params.shape[0] / k_fold)\n",
    "#extract the indexes of the parameters associated to each fold\n",
    "k_indices = np.array([idx[k * interval: (k + 1) * interval] for k in range(k_fold)])\n",
    "\n",
    "n_epoch = 3000\n",
    "rel_err = 0\n",
    "test_loss = 0\n",
    "abs_err=0\n",
    "\n",
    "for k in range(k_fold):\n",
    "\n",
    "    rel_err, abs_err, test_loss = cross_validation(k_indices, k, n_epoch)\n",
    "    rel_errors.append(rel_err)\n",
    "    abs_errors.append(abs_err)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(\"Mean relative error: \", np.mean(rel_errors))\n",
    "print(\"Mean absolute error: \", np.mean(abs_errors))\n",
    "print(\"Mean test loss: \", np.mean(test_losses))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
